使用的数据存储在多维Numpy数组中，也叫张量。张量是一个数据容器，它包含的数据几乎总是数值数据，因此它是数字的容器。张量的维度通常叫做轴

仅包含一个数字的张量叫做标量（scalar，标量张量，零维张量，0D张量），标量张量有0个轴(ndim=0)，张量轴的个数也叫作阶（rank）。

数字组成的数组叫做向量（vector）或一维张量（1D张量）。一维张量只有一个轴。x=np.array([12,14,24,66,78])，这个向量里面含有5个元素，所以被称为5D向量（！向量！！，不是张量）。维度可以表示沿着某个轴上的元素个数（比如5D向量），也可以表示张量中轴的个数。

向量组成的数组叫做矩阵（marix）或二维张量（2D张量）。矩阵有两个轴（通常叫做行和列），x=np.array([[6,89,67,23,0],[6,39,2,84,80],[4,13,43,45,5]])，第一个轴上的元素叫做行（row），第二个轴上的元素叫做列（column）。[6,89,67,23,0]是第一行，[6,6,4]是第一列

将多个矩阵组合成一个新的数组，可以得到一个3D张量。将多个3D张量组合成一个数组，可以创建一个4D张量

形状：这是一个整数元组，表示张量沿每个轴的维度大小（元素个数）。

数据类型（dtype）。这是张量中所包含数据的类型。例如，张量的类型可以是float32、unit8、float64等。在极少数情况下，你可能会遇到字符（char）张量。（Numpy以及大多数其他库中不存在字符串张量，因为张量中存储在预先分配的连续内存段中，而字符串的长度是可变的，无法用这种方式存储）

选择张量的特定元素叫作张量切片（tensor slicing）

relu：线性整流函数

较小的张量会被广播（broadcast），以匹配较大张量的形状。广播步骤：1）向较小的张量添加轴（广播轴），使其ndim与较大的张量相同
                                                                 2）将较小的张量沿着新轴重复，使其形状与较大的张量相同
                                                                
神经网络的基本数据结构是层。层是一个数据处理模块，将一个或者多个输入张量转换为一个或者多个输出张量

深度学习模型是层构成的有向无环图

模型在训练数据上的表现很好，并不意味着它在前所未见的数据上也会表现很好，而且真正关心的是模型在新数据上的性能

和mnist数据集一样，IMDB数据集也内置于Keras库。它已经过预处理：评论（单词序列）已经被转换为整数序列，其中每个整数代表字典中的某个单词

神经网络不能适用整数序列，必须把它转换为张量。转换方法有两种：1）填充列表：使列表具有相同的长度，再将列表转换成形状为（sample,word_indices)的整数张量，然后网络第一层使用能处理整数张量的层（即Embedding)。2）对列表进行One_hot编码，将其转换成0和1组成的向量。网络第一层可以用dense层，它能够处理浮点数向量数据

Dense（16，activation=‘relu’），传入Dense层的参数16是该层隐藏单元的个数。一个隐藏单元是该层表示空间的一个维度。每个带有relu激活的dense层都实现了output=relu（dot(w,input)+b)的运算，16个隐藏单元对应的权重矩阵w的形状为（input_dimension,16),与w做点积相当于将输入数据投影到16维表示空间中（再加上偏置向量b并应用relu运算）。可将表示空间的维度理解为网络学习内部表示时所拥有的自由度。隐藏单元越多（即更高维的表示空间），网络越能够学到更加复杂的表示，但网络的计算代价也变得更大，而且可能会导致学到不好的模式

对于Dense层的堆叠，需要确定两个关键架构：1）网络有多少层；2）每层有多少隐藏单元

如果没有relu等激活函数（也叫作非线性），Dense层将只包含两个线性运算———点积和加法：output=dot(w,input)+b   这样Dense层就只能学习输入数据的线性变换（仿射变换）：该层的假设空间是从输入数据到16位空间所有可能的线性变换集合。这种假设空间非常有限，无法利用多个层的优势，因为多个线性层堆叠实现的仍是线性运算，添加层数并不会扩展假设空间。为了得到更丰富的假设空间，从而充分利用多层表示的优势，需要添加非线性激活函数。relu是深度学习中最常用的激活函数。

对于输出概率值的模型，交叉熵（croddrntropy）往往是最好的选择

优化器是编译Keras模型必要的两个参数之一：
keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)
lr：大或等于0的浮点数，学习率；
momentum：大或等于0的浮点数，动量参数；
decay：大或等于0的浮点数，每次更新后的学习率衰减值；
nesterov：布尔值，确定是否使用Nesterov动量

keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-06)
lr：大或等于0的浮点数，学习率
rho：大或等于0的浮点数
epsilon：大或等于0的小浮点数，防止除0错误

过拟合：在第二轮之后，你对训练数据过度优化，最终学到的表示仅针对于训练数据，无法泛化到训练集之外的数据

如果要对N个类别的数据点进行分类，网络的最后一层应该是大小为N的Dense层
对于单标签、多分类问题，网络的最后一层应该使用softmax激活，这样就可以输出在N个输出类别上的概率分布
分类交叉熵将网络输出的概率分布与目标的真是分布之间的距离最小化

回归问题：预测一个连续值而不是离散的标签

不要将回归问题与logistic回归算法混为一谈，logistic回归不是回归算法，而是分类算法

将取值范围差异很大的数据输入到神经网络中，这是有问题的。网络可能会自动适应这种取值范围不同的数据，但学习就变得更加困难。对于这种数据，普遍采用的最佳实践是对每个特征做标准化，即对于输入数据的每个特征（输入数据矩阵中的列），减去特征平均值，载除以标准差，这样得到的特征平均值为0，标准差为1

回归问题使用的损失函数和分类问题不同，回归问题常用的损失函数是均方误差（MSE）
同样，回归问题实用的评估指标与分类问题也不同，精度的概念不适用与回归问题，常见的回归指标是平均绝对误差（MAE）
如果输入数据的特征具有不同的取值范围，应该先进行预处理，对每个特征单独进行缩放
如果可用数据很少，使用K折验证可以可靠评估模型
如果可用的训练数据很少，最好使用隐藏层较少（通常只有一到两个）的小型网络，以避免严重地过拟合

监督学习的目标是学习训练输入和训练目标之间的关系。
监督学习可以学会将输入数据映射到已知目标【也叫标书（annotation）】

无监督学习是指在没有目标的情况下寻找输入数据的有趣变换，其目的在于数据可视化、数据压缩、数据去噪或更好地理解数据中的相关性。
降维（dimensionality reduction）和聚类（clustering）是无监督学习的方法

自监督学习是没有人工标注的标签的监督学习。标签仍然存在，但他们是从输入数据中生成的，通常是使用启发式算法生成的

强化学习：智能体接受有关其环境的信息，并徐汇选择使其某种奖励最大化的行动

评估模型的重点是将数据划分为三个集合：训练集、验证集和测试集。在训练数据上训练模型，在验证数据上评估模型，一旦找到了最佳参数，就在测试数据上最后测试一次

三种经典的评估方法：简单的留出验证、K着验证，以及带有打乱数据的重复K折验证

简单的留出验证：留出一定比例的数据作为测试集。在剩余的数据上训练模型，然后在测试集上评估模型。

K折验证：将数据划分为大小相同的K个分区。对于每个分区i，在剩余的K-1个分区上训练模型，然后在分区i上评估模型。最终分数等于K个分数的平均值。对于不同的训练集—测试集划分，如果模型性能的变化很大，这种方法很有用。与留出验证一样，这种方法也需要独立的验证集进行模型校正

带有打乱数据的重复K折验证：如果可用数据相对较少，而又需要尽可能精确地评估模型，选择这种方式。具体做法是多次使用K折验证，在每次将数据划分为K个分区之前都先将数据打乱。最终分数是每次K折验证分数的平均值。这种方法一共要训练和评估P*K个模型（P是重复次数）

神经网络的数据预处理：目的是使原始数据更适于神经网络处理，包括向量化，标准化，处理缺失值和特征提取
向量化：神经网络的所有输入和目标都必须是浮点数张量（特定情况下可以是整数张量）。无论处理什么数据，都必须首先将其转换为张量，这一步就叫数据张量化
值标准化：一般来说，将取值相对较大的数据或异质数据输入到神经网络中是不安全的，这么做可能导致较大的梯度更新，进而导致网络无法收敛。为了让网络学习变得更容             易，输入的数据应该具有：取值较小、同质性两个特点
处理缺失值：一般来说，对于神经网络，将缺失值设置为0是安全的，只要0不是一个有意义的值。网络能够从数据中学到0意味着数据缺失，并且会忽略这个值。注意：如果测             试数据中可能有缺失值，而网络实在没有缺失值的数据上训练的，那么网络不可能学会忽略缺失值。在这种情况下，应该人为生成一些有缺失项的训练样本：               多次幅值一些训练样本，然后删除测试数据中可能缺失的某些特质

特征工程：将数据输入模型之前，利用你自己关于数据和机器学习算法（这里指神经网络）的知识对数据进行硬编码的转换（不是模型学到的），以改善模型的效果。多数情
          况下，一个机器学习模型无法从完全任意的数据中进行学习
          
优化是指调节模型以在训练数据上得到最佳性能（即机器学习中的学习），而泛化是指训练好的模型在前所未见的数据上的性能好坏。机器学习的目的是得到良好的泛化，但无法控制泛化，只能基于训练数据调节模型
训练开始时，优化和泛化是相关的：训练数据上的损失越小，测试数据上的损失也就越小。这时的模型是欠拟合的，即仍有改进的空间，网络还没有对训练数据中所有相关模式建模。但在训练数据上迭代一定次数后，泛化不再提高，验证指标先是不变，然后开始变差，即模型开始过拟合。这时模型开始学习仅和训练数据有关的模式。但这种模式对于新数据来说是错误的或者无关紧要的
为了防止模型从训练数据中学到 错误或者无关紧要的模式，最优解决方式是获取更多的训练数据。

这种降低过拟合的方法就叫做正则化：
1、减小网络大小：这是最简单的方法，即减少模型中可学习参数的个数。在深度学习中，参数更多的模型拥有更大的记忆容量，因此能够在训练样本和目标之间轻松地学会完美的字典映射。如果网络的记忆资源有限，则无法学会这种映射。同时，使用的模型应该具有足够多的参数以防止欠拟合。在容量过大和容量不足之间要找到一个折中。要找到合适的模型大小，一般的工作流程是开始时选择一个相对较少的层和参数，然后逐渐增加层的大小或者增加新层，知道这种增加对验证损失的印象变得很小
2、添加权重正则化：给定一些训练数据和一种网络架构，很多组权重值（即很多模型）都可以解释这些数据，简单模型比复杂模型更不容易过拟合（奥卡姆剃刀），这里的简单模型是指参数值分布的熵更小的模型。因此，一种常见的降低过拟合的方法就是强制让模型权重只能取较小的值，从而限制模型的复杂度，这使得权重值的分布更加规则，这种方法叫做权重正则化，其实现方法是向网络损失函数中添加与权重值相关的成本，这个成本有两种形式：1）L1正则化：添的成本与权重系数的绝对值成正比。2）L2正则化：添加的成本与权重系数的平方成正比。也叫权重衰减
3、dropout正则化：最有效最常用的正则化方式之一。对某一层使用dropout，就是在训练过程中随机将该层的一些输出特征舍弃（设置为0）。dropout比率是被设为0的特征所占的比例，通常在0.2-0.5之内。

机器学习的通用工作流程：问题定义、评估、特征工程、解决过拟合

卷积模型具有平移不变性和模式的空间层次结构
对于Keras的Conv2D层，这些参数都是向层传入的前几个参数：Cinv2D（outpuy_depth,(window_height,window_width))
卷积的工作原理：在3D输入特征图上滑动这些3*3或5*5的窗口，在每个可能的位置上停止并提取周围特征的3D图块[形状为(window_height,window_width,input_depth)]，然后每个3D图块与学到的同一个权重矩阵[叫做卷积核]做张量积，转换成形状为（output—depth，）的1D向量。然后对所有这些向量进行空间重组，使其转换为形状为（height,width,output_depth)的3D输出特征图。输出特征图中的每个空间位置都对应于输入特征图中的相同位置。
输出的宽度和高度可能与输入的宽度和高度不同。不同的原因可能有两点：边界效应，可以通过对输入特征图进行填充来抵消；使用了步幅

······
······
······
one_hot编码是将标记转换为向量的最常用、最基本的方法。它叫每个单词与一个唯一的整数索引相关联，然后将这个整数索引i转换为长度为N的二进制向量（N是词表大小），这个向量只有第i个元素是1，其余元素都为0

np.zeros（）生成相应大小的零矩阵

one-hot散列技巧，如果词表中唯一标记的数量太大而无法处理，使用这种技巧。这种方法没有为每个单词显式分配一个索引并将这些索引保存在一个字典中，而是将单词散列编码为固定长度的向量。

将单词与向量相关联还有另一种强大的方法，就是使用密集的词向量。one-hot编码得到的向量是二进制的、稀疏的（绝大部分元素都是0）、维度很高的（维度大小等于词表中的单词个数），而词嵌入式低维的浮点数向量（即密集向量，与稀疏向量相对）
获取词嵌入有两种方法：1）在完成主任务的同事学习词嵌入；2）在不同于待解决问题的机器学习任务上预计算好词嵌入，然后加载到模型中

合理的做法是对每个新任务都学习一个新的嵌入空间。

Embedding层至少需要两个参数：标记的个数和嵌入的维度
Embedding是层的输是一个二维整数张量，其形状为（samples，sequence_length），每个元素是一个整数序列。它能够嵌入长度可变的序列
······
······

循环神经网络（RNN）原理：生物智能以渐进的方式处理信息，同时保存一个关于所处理内容的内部模型，这个模型是根据过去的信息构建的，并随着新信息的进入而不断更新，以一个更加简化的版本：他处理序列的方式是，历遍所有序列元素，并保存一个状态，其中包含与已查看内容相关的信息。

对于第一个时间步，上一个时间步的输出没有定义，所以它没有当前状态，因此，需要将状态初始化为一个全零向量，这叫做网络的初始状态

np.stack(arrays, axis=0)则表示arrays[0], arrays[1], arrays[2]进行堆叠，所以结果与原始数组一样。
np.stack(arrays, axis=1)则表示arrays[0][0], arrays[1][0]和arrays[2][0]进行堆叠，然后是arrays[0][1]，arrays[1][1]与arrays[2][1]进行堆叠。
np.stack(arrays, axis=2)则表示arrays[0][0][0]，arrays[1][0][0]和arrays[2][0][0]进行堆叠，然后是arrays[0][0][1]，arrays[1][0][1]与arrays[2][0][1]进行堆叠，接着为arrays[0][0][2]，arrays[1][0][2]与arrays[2][0][2]进行堆叠......

SimpleRNN能够像其他Keras层一样处理序列张量，与Keras中的所有循环层一样，SimpleRNN可以在两种不同模式下运行：一种是返回每个时间步连续输出的完整序列，即形状为（batch_size,timesteps,output_features）的三维张量；另一种是只返回每个书序列的最终输出，即形状为（batch_size,output_features）的二维张量。这两种模式有return_sequences这个构造函数参数来控制。

model.fit():fit()函数   ：
fit( x, y, batch_size=32, epochs=10, verbose=1, callbacks=None,validation_split=0.0, validation_data=None, shuffle=True, 
class_weight=None, sample_weight=None, initial_epoch=0)

x：输入数据。如果模型只有一个输入，那么x的类型是numpy 
array，如果模型有多个输入，那么x的类型应当为list，list的元素是对应于各个输入的numpy array
y：标签，numpy array
batch_size：整数，指定进行梯度下降时每个batch包含的样本数。训练时一个batch的样本会被计算一次梯度下降，使目标函数优化一步。
epochs：整数，训练终止时的epoch值，训练将在达到该epoch值时停止，当没有设置initial_epoch时，它就是训练的总轮数，否则训练的总轮数为epochs - inital_epoch
verbose：日志显示，0为不在标准输出流输出日志信息，1为输出进度条记录，2为每个epoch输出一行记录
callbacks：list，其中的元素是keras.callbacks.Callback的对象。这个list中的回调函数将会在训练过程中的适当时机被调用，参考回调函数
validation_split：0~1之间的浮点数，用来指定训练集的一定比例数据作为验证集。验证集将不参与训练，并在每个epoch结束后测试的模型的指标，如损失函数、精确度等。注意，validation_split的划分在shuffle之前，因此如果你的数据本身是有序的，需要先手工打乱再指定validation_split，否则可能会出现验证集样本不均匀。
validation_data：形式为（X，y）的tuple，是指定的验证集。此参数将覆盖validation_spilt。
shuffle：布尔值或字符串，一般为布尔值，表示是否在训练过程中随机打乱输入样本的顺序。若为字符串“batch”，则是用来处理HDF5数据的特殊情况，它将在batch内部将数据打乱。
class_weight：字典，将不同的类别映射为不同的权值，该参数用来在训练过程中调整损失函数（只能用于训练）
sample_weight：权值的numpy 
array，用于在训练时调整损失函数（仅用于训练）。可以传递一个1D的与样本等长的向量用于对样本进行1对1的加权，或者在面对时序数据时，传递一个的形式为（samples，sequence_length）的矩阵来为每个时间步上的样本赋不同的权。这种情况下请确定在编译模型时添加了sample_weight_mode=’temporal’。
initial_epoch: 从该参数指定的epoch开始训练，在继续之前的训练时有用。
fit函数返回一个History的对象，其History.history属性记录了损失函数和其他指标的数值随epoch变化的情况，如果有验证集的话，也包含了验证集的这些指标变化情况

